{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2fpRUJYnDk0"
      },
      "source": [
        "#Chatgpt and langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHyThar_Yv9s",
        "outputId": "71a6a23f-a8f0-47ec-b4eb-a0ea0455e004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.8 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m1.5/1.8 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n",
            "Collecting langchain==0.0.316\n",
            "  Downloading langchain-0.0.316-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (3.9.3)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.0.316)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.0.316)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.43 (from langchain==0.0.316)\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.316) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.316) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.316) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.316)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.316)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.0.316)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.316) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.316) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.316) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.316) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.316) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.316) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.316) (3.0.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.316)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.316 langsmith-0.0.92 marshmallow-3.21.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.1\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken\n",
        "!pip install langchain==0.0.316\n",
        "!pip install openai==0.28.1\n",
        "!pip install python-dotenv\n",
        "!pip install faiss-cpu\n",
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttH6PpZoTClO"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import pandas as pd\n",
        "from langchain import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chains import RetrievalQA, LLMMathChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import Union, Any, List, Optional\n",
        "from langchain.document_loaders import (\n",
        "    WebBaseLoader, PyMuPDFLoader, TextLoader, Docx2txtLoader,\n",
        "    UnstructuredURLLoader, SeleniumURLLoader, PlaywrightURLLoader,\n",
        "    AsyncHtmlLoader, AsyncChromiumLoader, UnstructuredMarkdownLoader,\n",
        "    CSVLoader, JSONLoader, DataFrameLoader, UnstructuredImageLoader\n",
        "    )\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownTextSplitter\n",
        "from langchain.schema.document import Document\n",
        "from langchain.evaluation.qa import QAGenerateChain\n",
        "from langchain.chains.qa_generation.base import QAGenerationChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "import pickle\n",
        "from langchain.chains.chat_vector_db.prompts import QA_PROMPT\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.chat_vector_db.prompts import (\n",
        "    CONDENSE_QUESTION_PROMPT, QA_PROMPT\n",
        ")\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains import ConversationalRetrievalChain, RetrievalQAWithSourcesChain\n",
        "# from langchain.agents import create_csv_agent, create_pandas_dataframe_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "# import sharepy\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDNDd-14YoAs"
      },
      "outputs": [],
      "source": [
        "_ = load_dotenv(\"credentials.env\") # read local .env file\n",
        "\n",
        "openai.api_key  = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toTbLGitJ3wf"
      },
      "source": [
        "### Test chatbots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-GR4Mrjn6zu"
      },
      "outputs": [],
      "source": [
        "# Define the folder path where you want to search for .md files\n",
        "markdown_path = Path('sagemaker_documentation')\n",
        "\n",
        "data = []\n",
        "for file in markdown_path.glob('*.md'):\n",
        "    loader = TextLoader(str(file))\n",
        "    data += loader.load()\n",
        "\n",
        "text_splitter = MarkdownTextSplitter(\n",
        "    chunk_size=3000,\n",
        "    chunk_overlap=200,\n",
        ")\n",
        "data = text_splitter.split_documents(data)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "current_vectorstore = FAISS.from_documents(data, embeddings)\n",
        "\n",
        "# # Save vectorstore\n",
        "with open(\"sagemaker_documentation.pkl\", \"wb\") as f:\n",
        "    pickle.dump(current_vectorstore, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpOHUU_zux9T"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.chat_vector_db.prompts import (\n",
        "    CONDENSE_QUESTION_PROMPT, QA_PROMPT\n",
        ")\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains import ConversationalRetrievalChain, RetrievalQAWithSourcesChain\n",
        "\n",
        "\n",
        "# ConversationalRetrievalChain\n",
        "memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history\", return_messages=True, k=2\n",
        "    )\n",
        "\n",
        "question_gen_llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    verbose=False,\n",
        "    max_retries=2,\n",
        "    temperature=1\n",
        ")\n",
        "streaming_llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    # max_tokens=500,\n",
        "    verbose=False,\n",
        "    max_retries=2,\n",
        "    temperature=1\n",
        ")\n",
        "\n",
        "question_generator = LLMChain(\n",
        "    llm=question_gen_llm,\n",
        "    prompt=CONDENSE_QUESTION_PROMPT,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "doc_chain = load_qa_chain(\n",
        "    streaming_llm,\n",
        "    chain_type=\"stuff\",\n",
        "    prompt=QA_PROMPT,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "qa = ConversationalRetrievalChain(\n",
        "    retriever=current_vectorstore.as_retriever(search_kwargs={\"k\": 4}),\n",
        "    combine_docs_chain=doc_chain,\n",
        "    question_generator=question_generator,\n",
        "    memory=memory,\n",
        "    verbose=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "gFttoXtjMjad",
        "outputId": "3b637bcb-4abc-4d7c-fbca-cf8152408a39"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The cost of using Amazon SageMaker depends on various factors such as the instance type, storage, training time, and data transfer. It is best to refer to the AWS Pricing page for Amazon SageMaker or contact AWS support for specific pricing details.'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# qa.run(\"What is SageMaker?\")\n",
        "# qa.run(\"What are their Geospatial capabilities?\")\n",
        "qa.run(\"What is the cost\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkKUVK8i5dNF"
      },
      "outputs": [],
      "source": [
        "# RetrievalQAWithSourcesChain\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    verbose=True,\n",
        "    max_retries=1\n",
        ")\n",
        "\n",
        "qa = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=current_vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
        "    chain_type=\"stuff\",\n",
        "    return_source_documents=True,\n",
        ")\n",
        "qa(\"What are SageMaker Geospatial capabilities?\", return_only_outputs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTu__0Swvybt",
        "outputId": "1910ef0a-a137-4143-ef88-b0e4126e206c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer': 'The document does not provide information about SageMaker Geospatial capabilities.\\n',\n",
              " 'sources': 'N/A',\n",
              " 'source_documents': [Document(page_content='SageMaker geospatial capabilities roles\\n\\nAs a managed service, Amazon SageMaker geospatial capabilities perform operations on your behalf on the AWS hardware that is managed by SageMaker. It can perform only operations that the user permits.\\n\\nA user can grant these permissions with an IAM role (referred to as an execution role).\\n\\nTo create and use a locally available execution role, you can use the following procedures.\\n\\nCreate an execution role\\n\\nTo work with SageMaker geospatial capabilities you need to setup a user role and an execution role. A user role is an AWS identity with permission policies that determine what the user can and can not do within AWS. An execution role is an IAM role that grants the service permission to access your AWS resources. An execution role consists of permissions and trust policy. The trust policy specifies which principals have the permission to assume the role.\\n\\nUse the following procedure to create an execution role with the IAM managed policy, AmazonSageMakerGeospatialFullAccess, attached. If your use case requires more granular permissions, use other sections of this guide to create an execution role that meets your business needs.\\n\\nThe IAM managed policy,\\n\\nAdd Additional Amazon S3 Permissions to a SageMaker Execution Role.\\n\\nTo create a new role\\n\\nOpen the IAM console at https://console.aws.amazon.com/iam/.\\n\\nSelect Roles and then select Create role.\\n\\nSelect SageMaker.\\n\\nSelect Next: Permissions.\\n\\nThe IAM managed policy, AmazonSageMakerGeospatialFullAccess is automatically attached to this role. To see the permissions included in this policy, select the sideways arrow next to the policy name. Select Next: Tags.\\n\\n(Optional) Add tags and select Next: Review.\\n\\nGive the role a name in the text field under Role name and select Create role.\\n\\nIn the Roles section of the IAM console, select the role you just created. If needed, use the text box to search for the role using the role name you entered in step 7.\\n\\nOn the role summary page, make note of the ARN.\\n\\nPassing Roles\\n\\nActions like passing a role between services are a common function within SageMaker. You can find more details on Actions, Resources, and Condition Keys for SageMaker in the IAM User Guide.\\n\\nYou pass the role (iam:PassRole) when making these API calls: https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_geospatial_StartEarthObservationJob.html, https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_geospatial_StartVectorEnrichmentJob.html, https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_geospatial_ExportEarthObservationJob.html, https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_geospatial_ExportVectorEnrichmentJob.html.\\n\\nYou attach the following trust policy to the IAM role, which grants SageMaker principal permissions to assume the role, and is the same for all of the execution roles:', metadata={'source': 'markdowns1/sagemaker-geospatial-roles.md'}),\n",
              "  Document(page_content='Working with Amazon SageMaker\\n\\nAmazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models. See the following resources for complete code examples with instructions.\\n\\nLink to Github\\n\\nLink to AWS Code Sample Catalog', metadata={'source': 'markdowns1/examples-sagemaker.md'}),\n",
              "  Document(page_content='Buy and Sell Amazon SageMaker Algorithms and Models in AWS Marketplace\\n\\nAmazon SageMaker integrates with AWS Marketplace, enabling developers to charge other SageMaker users for the use of their algorithms and model packages. AWS Marketplace is a curated digital catalog that makes it easy for customers to find, buy, deploy, and manage third-party software and services that customers need to build solutions and run their businesses. AWS Marketplace includes thousands of software listings in popular categories, such as security, networking, storage, machine learning, business intelligence, database, and DevOps. It simplifies software licensing and procurement with flexible pricing options and multiple deployment methods.\\n\\nFor information, see AWS Marketplace Documentation.\\n\\nTopics\\n\\nSageMaker Algorithms\\n\\nSageMaker Model Packages\\n\\nSell Amazon SageMaker Algorithms and Model Packages\\n\\nFind and Subscribe to Algorithms and Model Packages on AWS Marketplace\\n\\nUse Algorithm and Model Package Resources\\n\\nSageMaker Algorithms\\n\\nAn algorithm enables you to perform end-to-end machine learning. It has two logical components: training and inference. Buyers can use the training component to create training jobs in SageMaker and build a machine learning model. SageMaker saves the model artifacts generated by the algorithm during training to an Amazon S3 bucket. For more information, see Train a Model with Amazon SageMaker.\\n\\nBuyers use the inference component with the model artifacts generated during a training job to create a deployable model in their SageMaker account. They can use the deployable model for real-time inference by using SageMaker hosting services. Or, they can get inferences for an entire dataset by running batch transform jobs. For more information, see Deploy a Model in Amazon SageMaker.\\n\\nSageMaker Model Packages\\n\\nBuyers use a model package to build a deployable model in SageMaker. They can use the deployable model for real-time inference by using SageMaker hosting services. Or, they can get inferences for an entire dataset by running batch transform jobs. For more information, see Deploy a Model in Amazon SageMaker. As a seller, you can build your model artifacts by training in SageMaker, or you can use your own model artifacts from a model that you trained outside of SageMaker. You can charge buyers for inference.\\n\\nTopics', metadata={'source': 'markdowns1/sagemaker-marketplace.md'}),\n",
              "  Document(page_content=\"How Amazon SageMaker uses AWS Secrets Manager\\n\\nSageMaker is a fully managed machine learning service. With SageMaker, data scientists and developers can quickly and easily build and train machine learning models, and then directly deploy them into a production-ready hosted environment. It provides an integrated Jupyter authoring notebook instance for easy access to your data sources for exploration and analysis, so you don't have to manage servers.\\n\\nYou can associate Git repositories with your Jupyter notebook instances to save your notebooks in a source control environment that persists even if you stop or delete your notebook instance. You can manage your private repositories credentials using Secrets Manager. For more information, see Associate Git Repositories with Amazon SageMaker Notebook Instances in the Amazon SageMaker Developer Guide.\\n\\nTo import data from Databricks, Data Wrangler stores your JDBC URL in Secrets Manager. For more information, see Import data from Databricks (JDBC).\\n\\nTo import data from Snowflake, Data Wrangler stores your credentials in a Secrets Manager secret. For more information, see Import data from Snowflake.\", metadata={'source': 'markdowns1/integrating-sagemaker.md'}),\n",
              "  Document(page_content='Using Your Own Algorithms with Amazon SageMaker.\\n\\nSome interruptions\\n\\nAn MD5 hash of the training algorithm that identifies the Docker image used for training.\\n\\nSome interruptions\\n\\nThe Amazon S3 path where the model artifacts, which result from model training, are stored. This path must point to a single\\n\\nThe model artifacts must be in an S3 bucket that is in the same region as the model package.\\n\\nSome interruptions\\n\\nA structure with Model Input details.\\n\\nModelInput\\n\\nSome interruptions\\n\\nThe name of a pre-trained machine learning benchmarked by Amazon SageMaker Inference Recommender model that matches your model. You can find a list of benchmarked models by calling\\n\\nSome interruptions\\n\\nThe AWS Marketplace product ID of the model package.\\n\\nSome interruptions', metadata={'source': 'markdowns1/aws-properties-sagemaker-modelpackage-modelpackagecontainerdefinition.md'})]}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# qa(\"What is SageMaker?\", return_only_outputs=True)\n",
        "# qa(\"What are all AWS regions where AWS SageMaker is available?\", return_only_outputs=True)\n",
        "# qa(\"What do you know about AWS regions? is AWS SageMaker available on them?\", return_only_outputs=True)\n",
        "# qa(\"How to check if an endpoint is KMS encrypted?\", return_only_outputs=True)\n",
        "qa(\"What are SageMaker Geospatial capabilities?\", return_only_outputs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkFp8yQT9n2u",
        "outputId": "32fe85b1-a74e-4161-c6c7-44deecb362f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# result = qa(\"What is SageMaker?\", return_only_outputs=True)\n",
        "# result = qa(\"What are all AWS regions where AWS SageMaker is available?\", return_only_outputs=True)\n",
        "# result = qa(\"How to check if an endpoint is KMS encrypted?\", return_only_outputs=True)\n",
        "result = qa(\"What are SageMaker Geospatial capabilities?\", return_only_outputs=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaCoUjBFEunc"
      },
      "source": [
        "## Test dataframe agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AyBCesDxmaM"
      },
      "outputs": [],
      "source": [
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"unidadesnegocio.csv\")\n",
        "\n",
        "agent = create_pandas_dataframe_agent(\n",
        "    ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\n",
        "    df,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "ghwsGEstx_ZI",
        "outputId": "b242cb17-4bf1-42b8-be27-2e9a8fb9368a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mEl precio del procedimiento USG abdomen inferior es de 457.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'El precio del procedimiento USG abdomen inferior es de 457.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"¿Cuál es el precio del procedimiento USG abdomen inferior?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "PcLdIVt5ySP7",
        "outputId": "9a2a4e86-6092-436d-feca-5573b56dc456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mPara obtener los precios de un ultrasonido de mamas en el dataframe `df`, podemos filtrar las filas que corresponden a esta categoría y luego seleccionar la columna de precios. Aquí está el código para hacerlo:\n",
            "\n",
            "```python\n",
            "precios_mamas = df[df['SUBCATEGORIA'] == 'USG MAMARIO']['PRECIO']\n",
            "```\n",
            "\n",
            "Esto creará una serie de pandas con los precios de los ultrasonidos de mamas. Puedes imprimir esta serie para ver los precios.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Para obtener los precios de un ultrasonido de mamas en el dataframe `df`, podemos filtrar las filas que corresponden a esta categoría y luego seleccionar la columna de precios. Aquí está el código para hacerlo:\\n\\n```python\\nprecios_mamas = df[df['SUBCATEGORIA'] == 'USG MAMARIO']['PRECIO']\\n```\\n\\nEsto creará una serie de pandas con los precios de los ultrasonidos de mamas. Puedes imprimir esta serie para ver los precios.\""
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"¿Cuáles son los precios de un ultrasonido de mamas?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "jgZivsDdybBS",
        "outputId": "ec77e81f-ddb1-456f-ea31-dedcbb1fdb43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mEl tiempo de entrega de un ultrasonido de mamas es \"ENTREGA EN MOMENTO/ INFORME POR CORREO 1 HORA POST PROCEDIMIENTO\".\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'El tiempo de entrega de un ultrasonido de mamas es \"ENTREGA EN MOMENTO/ INFORME POR CORREO 1 HORA POST PROCEDIMIENTO\".'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# agent.run(\"¿Cuáles son las unidades de negocio disponibles?\")\n",
        "# agent.run(\"¿Cuáles son las categorias disponibles dentro de la unidad de negocio RADIOLOGIA?\")\n",
        "agent.run(\"¿Cuál es el tiempo de entrega de un ultrasonido de mamas?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "8HqwcjTmy1Qe",
        "outputId": "f357487c-6ee8-49c0-d606-da987d020b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `df[df['NOMBRE'] == 'HEMATOLOGIA COMPLETA']['PRECIO'].values[0]`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m116.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `df[df['NOMBRE'] == 'USG ABDOMEN INFERIOR']['PRECIO'].values[0]`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m457.0\u001b[0m\u001b[32;1m\u001b[1;3mEl precio de una hematología completa es de 116.0 y el precio de un USG abdomen inferior es de 457.0.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'El precio de una hematología completa es de 116.0 y el precio de un USG abdomen inferior es de 457.0.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"¿Cuáles son los precios de una hematología completa y el precio de USG abdomen inferior?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "FyfAVLwizASh",
        "outputId": "32266a2d-b47e-4c38-f655-f7512fec01fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `df[df['NOMBRE'].isin(['HEMATOLOGIA COMPLETA', 'USG ABDOMEN INFERIOR'])]['PRECIO'].sum()`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m573.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `df[df['NOMBRE'] == 'HEMATOLOGIA COMPLETA']['PRECIO'].values[0]`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m116.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `df[df['NOMBRE'] == 'USG ABDOMEN INFERIOR']['PRECIO'].values[0]`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m457.0\u001b[0m\u001b[32;1m\u001b[1;3mLa suma de los precios de una hematología completa y de USG abdomen inferior es de 573.0. \n",
            "\n",
            "El precio individual de la hematología completa es de 116.0 y el precio individual del USG abdomen inferior es de 457.0.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'La suma de los precios de una hematología completa y de USG abdomen inferior es de 573.0. \\n\\nEl precio individual de la hematología completa es de 116.0 y el precio individual del USG abdomen inferior es de 457.0.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"¿Cuáles es la suma de los precios de una hematología completa y de USG abdomen inferior y cuáles son sus precios individuales?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "id": "NwkfFeeZqFA6",
        "outputId": "03b47403-8300-4cb2-fe05-8a89e2ec4373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `{'query': \"df[df['NOMBRE'] == 'RESONANCIA MAGNETICA DE ABDOMEN SUPERIOR']\"}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m    UNIDAD DE NEGOCIO                   CATEGORIA SUBCATEGORIA  \\\n",
            "222        RADIOLOGIA  RESONANCIA MAGNETICA (RMN)      NINGUNA   \n",
            "\n",
            "    REFERENCIA (SI/NO)                                    NOMBRE  \\\n",
            "222                 SI  RESONANCIA MAGNETICA DE ABDOMEN SUPERIOR   \n",
            "\n",
            "    OTROS NOMBRES  PRECIO  PRECIO DESCUENTO VIVOLIFE  CODIGO SAM  \\\n",
            "222           NaN  2779.7                     2779.7      2680.0   \n",
            "\n",
            "    OBSERVACIONES PREPARACION  \\\n",
            "222           NaN         NaN   \n",
            "\n",
            "                                     TIEMPO DE ENTREGA  \\\n",
            "222  VARIA DE ACUERDO AL CENTRO DE DIAGNOSTICO AL C...   \n",
            "\n",
            "                                       TIPO DE MUESTRA  \\\n",
            "222  SE REALIZA LECTURA DE FORMA PRESENCIAL CON INS...   \n",
            "\n",
            "                                               CONTEXT  \n",
            "222  informacion sobre precios de procedimientos, e...  \u001b[0m\u001b[32;1m\u001b[1;3mLa información disponible sobre \"RESONANCIA MAGNETICA DE ABDOMEN SUPERIOR\" es la siguiente:\n",
            "\n",
            "- Unidad de Negocio: RADIOLOGIA\n",
            "- Categoría: RESONANCIA MAGNETICA (RMN)\n",
            "- Subcategoría: NINGUNA\n",
            "- Referencia (Si/No): SI\n",
            "- Nombre: RESONANCIA MAGNETICA DE ABDOMEN SUPERIOR\n",
            "- Otros Nombres: No se especifica\n",
            "- Precio: 2779.7\n",
            "- Precio Descuento Vivolife: 2779.7\n",
            "- Código SAM: 2680.0\n",
            "- Observaciones: No se especifica\n",
            "- Preparación: No se especifica\n",
            "- Tiempo de Entrega: VARIA DE ACUERDO AL CENTRO DE DIAGNOSTICO AL CUAL SE REFIERA\n",
            "- Tipo de Muestra: SE REALIZA LECTURA DE FORMA PRESENCIAL CON INSTRUMENTAL DE RADIOLOGIA\n",
            "- Contexto: Información sobre precios de procedimientos, exámenes\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'La información disponible sobre \"RESONANCIA MAGNETICA DE ABDOMEN SUPERIOR\" es la siguiente:\\n\\n- Unidad de Negocio: RADIOLOGIA\\n- Categoría: RESONANCIA MAGNETICA (RMN)\\n- Subcategoría: NINGUNA\\n- Referencia (Si/No): SI\\n- Nombre: RESONANCIA MAGNETICA DE ABDOMEN SUPERIOR\\n- Otros Nombres: No se especifica\\n- Precio: 2779.7\\n- Precio Descuento Vivolife: 2779.7\\n- Código SAM: 2680.0\\n- Observaciones: No se especifica\\n- Preparación: No se especifica\\n- Tiempo de Entrega: VARIA DE ACUERDO AL CENTRO DE DIAGNOSTICO AL CUAL SE REFIERA\\n- Tipo de Muestra: SE REALIZA LECTURA DE FORMA PRESENCIAL CON INSTRUMENTAL DE RADIOLOGIA\\n- Contexto: Información sobre precios de procedimientos, exámenes'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"¿Puedes decirme toda la información posible de RESONANCIA MAGNETICA DE ABDOMEN SUPERIOR?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxjXRn19F8eI"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def show_results_status(pacient_name: str) -> str:\n",
        "    \"Show the results of medical exams if client ask or assistant needs it\"\n",
        "    return f\"\"\"\n",
        "    A continuación se muestran el estatus de los resultados para el paciente {pacient_name}\n",
        "\n",
        "    Exámenes radiología:\n",
        "    - Ultrasonografía pélvico: Completado\n",
        "    - Ultrasonografía obstétrico: Completado\n",
        "\n",
        "    Exámenes laboratorios:\n",
        "    - Panel de parásitos: Completado\n",
        "    - Helicobacter piloris: Pendiente\n",
        "    - influenza de covid: Pendiente\n",
        "\n",
        "    Informes médicos:\n",
        "    - Informes: Pendientes\n",
        "\n",
        "    De momento podemos están completos los examenes de radiología únicamente\n",
        "    \"\"\"\n",
        "\n",
        "@tool\n",
        "def validate_email(email: str) -> str:\n",
        "    \"When AI assistant needs to validate if the email is correct\"\n",
        "    return f\"\"\"\n",
        "    Can you confirm if email is correct?:\n",
        "      - {email}\n",
        "    \"\"\"\n",
        "\n",
        "@tool\n",
        "def send_results(pacient_name: str, email: str) -> str:\n",
        "    \"When the client confirms that all the email is correct, send the results\"\n",
        "\n",
        "    return f\"\"\"\n",
        "    La información del paciente {pacient_name} ha sido enviada al correo {email}! Revisa tu correo en unos minutos\n",
        "    y no te olvides de revisar el spam\n",
        "    \"\"\"\n",
        "\n",
        "tools = [show_results_status, validate_email, send_results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIQQOb-NNuvv"
      },
      "outputs": [],
      "source": [
        "PREFIX = \"\"\"You are an Assistant that gives medical exams results.\n",
        "\n",
        "When the client ask for results of medical exams, guide the client through next sequence of questions: \\\n",
        "\n",
        "First, ask the client the pacient name \\\n",
        "Second, show results status of the pacient name and ask if the client wants to recieve the exams results in his emal, if yes, ask the client the email \\\n",
        "Third, validate if the email is correct \\\n",
        "\n",
        "Finally, if the client confirms that the information is correct, send the results to the email.\n",
        "\"\"\"\n",
        "\n",
        "SUFFIX  = \"\"\"Begin!\n",
        "Previous conversation history:\n",
        "{chat_history}\n",
        "New input: {input}\n",
        "{agent_scratchpad}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2f27GK4OoM1"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "# prompt.pretty_print()-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSTitvqFOslE"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "messages = [\n",
        "            SystemMessagePromptTemplate.from_template(PREFIX),\n",
        "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "            HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "        ]\n",
        "\n",
        "prompt.messages = messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBGEv-atlSRI"
      },
      "source": [
        "## Test agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HORrUTEOvQK",
        "outputId": "a9d351a9-7492-4f9d-e141-0951c5bd3a6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 248,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "agent = create_openai_tools_agent(model, tools, prompt)\n",
        "\n",
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, return_intermediate_steps=True)\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "memory.buffer_as_messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A9rQ-VhO2yM"
      },
      "outputs": [],
      "source": [
        "def invoke_agent(input: str):\n",
        "    result = agent_executor.invoke(\n",
        "        {\n",
        "            \"input\": input,\n",
        "            \"chat_history\": memory.buffer_as_messages\n",
        "        }\n",
        "    )\n",
        "\n",
        "    result.pop('chat_history')\n",
        "    memory.save_context({\"input\": result['input']}, {\"output\": result['output']})\n",
        "    print(result['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nodoVcTLO7xj",
        "outputId": "d14acb26-30cf-470d-9724-2259b99ed35b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m¡Hola! Buenas tardes. ¿En qué puedo ayudarte hoy?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "¡Hola! Buenas tardes. ¿En qué puedo ayudarte hoy?\n"
          ]
        }
      ],
      "source": [
        "invoke_agent('Hola buenas tardes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjJuGQyTO89r",
        "outputId": "f0c94879-07b6-4fc2-b546-229305195960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mClaro, puedo ayudarte con eso. ¿Podrías proporcionarme el nombre del paciente?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Claro, puedo ayudarte con eso. ¿Podrías proporcionarme el nombre del paciente?\n"
          ]
        }
      ],
      "source": [
        "invoke_agent('quiero consultar el estado de mis examenes de laboratorio')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irRqfu2TPDc-",
        "outputId": "b6aab4d3-e250-4b9e-8217-82a9f6b544fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `show_results_status` with `{'pacient_name': 'Luis Fernando Martinez López'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
            "    A continuación se muestran el estatus de los resultados para el paciente Luis Fernando Martinez López\n",
            "\n",
            "    Exámenes radiología:\n",
            "    - Ultrasonografía pélvico: Completado\n",
            "    - Ultrasonografía obstétrico: Completado\n",
            "\n",
            "    Exámenes laboratorios:\n",
            "    - Panel de parásitos: Completado\n",
            "    - Helicobacter piloris: Pendiente\n",
            "    - influenza de covid: Pendiente\n",
            "\n",
            "    Informes médicos:\n",
            "    - Informes: Pendientes\n",
            "\n",
            "    De momento podemos están completos los examenes de radiología únicamente\n",
            "    \u001b[0m\u001b[32;1m\u001b[1;3mLos resultados de los exámenes de laboratorio para el paciente Luis Fernando Martinez López son los siguientes:\n",
            "\n",
            "- Exámenes de radiología:\n",
            "  - Ultrasonografía pélvica: Completado\n",
            "  - Ultrasonografía obstétrica: Completado\n",
            "\n",
            "- Exámenes de laboratorio:\n",
            "  - Panel de parásitos: Completado\n",
            "  - Helicobacter pylori: Pendiente\n",
            "  - Influenza de COVID-19: Pendiente\n",
            "\n",
            "- Informes médicos:\n",
            "  - Informes: Pendientes\n",
            "\n",
            "Actualmente, solo se han completado los exámenes de radiología. ¿Te gustaría recibir los resultados por correo electrónico?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Los resultados de los exámenes de laboratorio para el paciente Luis Fernando Martinez López son los siguientes:\n",
            "\n",
            "- Exámenes de radiología:\n",
            "  - Ultrasonografía pélvica: Completado\n",
            "  - Ultrasonografía obstétrica: Completado\n",
            "\n",
            "- Exámenes de laboratorio:\n",
            "  - Panel de parásitos: Completado\n",
            "  - Helicobacter pylori: Pendiente\n",
            "  - Influenza de COVID-19: Pendiente\n",
            "\n",
            "- Informes médicos:\n",
            "  - Informes: Pendientes\n",
            "\n",
            "Actualmente, solo se han completado los exámenes de radiología. ¿Te gustaría recibir los resultados por correo electrónico?\n"
          ]
        }
      ],
      "source": [
        "invoke_agent('Luis Fernando Martinez López')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT8dUC6EPJS4",
        "outputId": "2338cbbb-d1d2-4d64-f2bf-bcde79b2f8fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mPerfecto. ¿Podrías proporcionarme tu dirección de correo electrónico para enviarte los resultados?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Perfecto. ¿Podrías proporcionarme tu dirección de correo electrónico para enviarte los resultados?\n"
          ]
        }
      ],
      "source": [
        "invoke_agent('si por favor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piQ56i0bP42D",
        "outputId": "e9d0195b-3ce8-4eb3-fd20-8823d00988ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `validate_email` with `{'email': 'pajarito@gmail.com'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
            "    Can you confirm if email is correct?:\n",
            "      - pajarito@gmail.com\n",
            "    \u001b[0m\u001b[32;1m\u001b[1;3m¿Podrías confirmar si el correo electrónico es correcto? El correo electrónico proporcionado es pajarito@gmail.com. ¿Es correcto?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "¿Podrías confirmar si el correo electrónico es correcto? El correo electrónico proporcionado es pajarito@gmail.com. ¿Es correcto?\n"
          ]
        }
      ],
      "source": [
        "invoke_agent('mi correo es pajarito@gmail.com')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnm7NuG0P_pZ",
        "outputId": "366d6361-6a79-47c1-b65c-508523c27f8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `send_results` with `{'pacient_name': 'Luis Fernando Martinez López', 'email': 'pajarito@gmail.com'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m\n",
            "    La información del paciente Luis Fernando Martinez López ha sido enviada al correo pajarito@gmail.com! Revisa tu correo en unos minutos\n",
            "    y no te olvides de revisar el spam\n",
            "    \u001b[0m\u001b[32;1m\u001b[1;3m¡Perfecto! La información del paciente Luis Fernando Martinez López ha sido enviada al correo pajarito@gmail.com. Por favor, revisa tu correo en unos minutos y no olvides revisar la carpeta de spam por si acaso. Si tienes alguna otra pregunta, no dudes en hacerla.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "¡Perfecto! La información del paciente Luis Fernando Martinez López ha sido enviada al correo pajarito@gmail.com. Por favor, revisa tu correo en unos minutos y no olvides revisar la carpeta de spam por si acaso. Si tienes alguna otra pregunta, no dudes en hacerla.\n"
          ]
        }
      ],
      "source": [
        "invoke_agent('Si, es correcto')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
